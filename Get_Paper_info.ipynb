{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Paper Info\n",
    "These notebook will get the paper info for each speakers in the conference. The attributes are: Number of papers (by year), first paper year, number of citation (by year), country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run setup.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invited"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append all files in Data folder as a datafrom, and add a column for the file name without the extension and folder name\n",
    "df_new  = pd.read_csv(os.path.join(filepath,'factInvited_init.csv'), encoding='utf-8')\n",
    "# df_base  = pd.read_csv(os.path.join(filepath,'factInvited.csv'), encoding='utf-8')\n",
    "\n",
    "# Find new names\n",
    "# df_new = df_new[~df_new['Full name'].isin(df_base['Full name'])].reset_index(drop=True)\n",
    "\n",
    "dblp_name = df_new['Full name'].str.replace(' ', '%20')\n",
    "dblp_name = dblp_name.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# drop nan values from the list\n",
    "dblp_name = dblp_name.dropna().reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data from dblp.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1124/1124 [1:26:47<00:00,  4.63s/it] \n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame(columns = ['Full name','Year','Year Count'])\n",
    "\n",
    "for Author in tqdm(dblp_name):\n",
    "    author_list = []\n",
    "    paper_list = []\n",
    "    \n",
    "    ##### Check if author is on dblp #####\n",
    "    dblp_URL = \"https://dblp.org/search?q=\" + Author\n",
    "    page = requests.get(dblp_URL)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    control_check = soup.find(id=\"completesearch-authors\").find_all(\"ul\",class_ = \"result-list\")\n",
    "    if len(control_check) > 0:\n",
    "        first_author = soup.find(id=\"completesearch-authors\").find_all(\"ul\",class_ = \"result-list\")[0].find_all(\"a\",href=True)[0]['href']\n",
    "        # print(Author,\" is on the webpage and the process continues...\")\n",
    "        \n",
    "        ##### Get info from author #####\n",
    "        author_page = requests.get(first_author)\n",
    "        soup_of_speaker = BeautifulSoup(author_page.content, \"html.parser\")\n",
    "\n",
    "        Year_list = []\n",
    "\n",
    "        sections = soup_of_speaker.find(id=\"publ-section\").find_all(\"div\", class_=\"hide-body\")\n",
    "        for s in range(0,len(sections)): # Nu går vi ind på hver enkelt sektion\n",
    "            rows_in_sections = sections[s].find_all('ul', class_=\"publ-list\")[0].findAll(True, {\"class\":['year','entry inproceedings toc','entry article toc','entry incollection toc', 'entry book toc','entry editor toc','entry reference toc']})\n",
    "            last_row_idx = 0\n",
    "            \n",
    "            for row in range(0,len(rows_in_sections)): # Nu går vi ind på hver enkelt række\n",
    "                #### Append year multipliers\n",
    "                if rows_in_sections[row].p == None:\n",
    "                    Year_list.append(rows_in_sections[row].text)\n",
    "                    paper_list.append(row-last_row_idx-1)\n",
    "                    last_row_idx = row \n",
    "                if row == len(rows_in_sections)-1: # den sidste linje i hver sektion\n",
    "                    paper_list.append(len(rows_in_sections)-last_row_idx-1)\n",
    "            \n",
    "            # remove all -1 values from the list\n",
    "            paper_list = [x for x in paper_list if x >= 0]\n",
    "                \n",
    "        # create a dataframe\n",
    "        df2 = pd.DataFrame(columns = ['Full name','Year','Year Count'])\n",
    "        # append full name to the dataframe\n",
    "        \n",
    "        df2['Year'] = Year_list\n",
    "        df2['Year Count'] = paper_list\n",
    "        df2['Full name'] = Author\n",
    "        df1 = df1.append(df2, ignore_index=True)\n",
    "    time.sleep(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(os.path.join(filepath,\"paper_count_Invited_new.csv\"), index=False)\n",
    "df3 = df1.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine data and save as factTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the initial factTable\n",
    "df  = pd.read_csv(os.path.join(filepath,'factInvited_init.csv'), encoding='utf-8')\n",
    "# Load the table with paper count per year\n",
    "# df2 = pd.read_csv(os.path.join(filepath,'paper_count_per_year_proceedings.csv'), encoding='utf-8')\n",
    "# concat df1 and df2\n",
    "# df1 = pd.concat([df2,df3], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Full name'] = df1['Full name'].str.replace('%20', ' ')\n",
    "df1 = df1.drop_duplicates().reset_index(drop=True)\n",
    "df1['Year'] = df1['Year'].astype(int)\n",
    "df1['Year Count'] = df1['Year Count'].astype(int)\n",
    "\n",
    "df1 = df1.sort_values(by=['Year'], ascending=True)\n",
    "\n",
    "df1['Year Count'] = df1.groupby('Full name')['Year Count'].cumsum()\n",
    "\n",
    "df1['max_year_count'] = df1.groupby('Full name')['Year Count'].transform('max')\n",
    "df1['First year paper'] = df1.groupby('Full name')['Year'].transform('min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in original table: 1334  and umber of rows in merged table: 1334\n",
      "Pct. of speakers whose information I was able to collect 99.62 %\n",
      "The file is now saved\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Full name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Conference (short)</th>\n",
       "      <th>First name</th>\n",
       "      <th>Middle name</th>\n",
       "      <th>Last name</th>\n",
       "      <th>gender</th>\n",
       "      <th>Paper Count</th>\n",
       "      <th>Max Paper Count</th>\n",
       "      <th>First year paper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gary L. Baldwi</td>\n",
       "      <td>2004</td>\n",
       "      <td>ASPDAC</td>\n",
       "      <td>Gary</td>\n",
       "      <td>L.</td>\n",
       "      <td>Baldwi</td>\n",
       "      <td>M</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1962.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rudy Lauwereins</td>\n",
       "      <td>2004</td>\n",
       "      <td>ASPDAC</td>\n",
       "      <td>Rudy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lauwereins</td>\n",
       "      <td>M</td>\n",
       "      <td>112</td>\n",
       "      <td>196.0</td>\n",
       "      <td>1987.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rajeev Madhavan</td>\n",
       "      <td>2005</td>\n",
       "      <td>ASPDAC</td>\n",
       "      <td>Rajeev</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Madhavan</td>\n",
       "      <td>M</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1994.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jan M. Rabaey</td>\n",
       "      <td>2005</td>\n",
       "      <td>ASPDAC</td>\n",
       "      <td>Jan</td>\n",
       "      <td>M.</td>\n",
       "      <td>Rabaey</td>\n",
       "      <td>M</td>\n",
       "      <td>146</td>\n",
       "      <td>321.0</td>\n",
       "      <td>1985.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alberto Sangiovanni-Vincentelli</td>\n",
       "      <td>2006</td>\n",
       "      <td>ASPDAC</td>\n",
       "      <td>Alberto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sangiovanni-Vincentelli</td>\n",
       "      <td>M</td>\n",
       "      <td>458</td>\n",
       "      <td>691.0</td>\n",
       "      <td>1973.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Satoru Ito</td>\n",
       "      <td>2006</td>\n",
       "      <td>ASPDAC</td>\n",
       "      <td>Satoru</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ito</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rob Rutenbar</td>\n",
       "      <td>2007</td>\n",
       "      <td>ASPDAC</td>\n",
       "      <td>Rob</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rutenbar</td>\n",
       "      <td>M</td>\n",
       "      <td>115</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1981.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jan M. Rabaey</td>\n",
       "      <td>2008</td>\n",
       "      <td>ASPDAC</td>\n",
       "      <td>Jan</td>\n",
       "      <td>M.</td>\n",
       "      <td>Rabaey</td>\n",
       "      <td>M</td>\n",
       "      <td>185</td>\n",
       "      <td>321.0</td>\n",
       "      <td>1985.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mitsuo Saito</td>\n",
       "      <td>2009</td>\n",
       "      <td>ASPDAC</td>\n",
       "      <td>Mitsuo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Saito</td>\n",
       "      <td>M</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1985.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wolfgang Rosenstiel</td>\n",
       "      <td>2009</td>\n",
       "      <td>ASPDAC</td>\n",
       "      <td>Wolfgang</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rosenstiel</td>\n",
       "      <td>M</td>\n",
       "      <td>261</td>\n",
       "      <td>471.0</td>\n",
       "      <td>1981.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Full name  Year Conference (short) First name  \\\n",
       "0                   Gary L. Baldwi  2004             ASPDAC       Gary   \n",
       "1                  Rudy Lauwereins  2004             ASPDAC       Rudy   \n",
       "2                  Rajeev Madhavan  2005             ASPDAC     Rajeev   \n",
       "3                    Jan M. Rabaey  2005             ASPDAC        Jan   \n",
       "4  Alberto Sangiovanni-Vincentelli  2006             ASPDAC    Alberto   \n",
       "5                       Satoru Ito  2006             ASPDAC     Satoru   \n",
       "6                     Rob Rutenbar  2007             ASPDAC        Rob   \n",
       "7                    Jan M. Rabaey  2008             ASPDAC        Jan   \n",
       "8                     Mitsuo Saito  2009             ASPDAC     Mitsuo   \n",
       "9              Wolfgang Rosenstiel  2009             ASPDAC   Wolfgang   \n",
       "\n",
       "  Middle name                Last name gender  Paper Count  Max Paper Count  \\\n",
       "0          L.                   Baldwi      M            4              4.0   \n",
       "1         NaN               Lauwereins      M          112            196.0   \n",
       "2         NaN                 Madhavan      M            5              5.0   \n",
       "3          M.                   Rabaey      M          146            321.0   \n",
       "4         NaN  Sangiovanni-Vincentelli      M          458            691.0   \n",
       "5         NaN                      Ito      M            3              3.0   \n",
       "6         NaN                 Rutenbar      M          115            172.0   \n",
       "7          M.                   Rabaey      M          185            321.0   \n",
       "8         NaN                    Saito      M            7              7.0   \n",
       "9         NaN               Rosenstiel      M          261            471.0   \n",
       "\n",
       "   First year paper  \n",
       "0            1962.0  \n",
       "1            1987.0  \n",
       "2            1994.0  \n",
       "3            1985.0  \n",
       "4            1973.0  \n",
       "5            2000.0  \n",
       "6            1981.0  \n",
       "7            1985.0  \n",
       "8            1985.0  \n",
       "9            1981.0  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a function to get the paper count for a given name and year\n",
    "def get_paper_count(name, year):\n",
    "    df = df1[df1['Full name'] == name]\n",
    "    paper_count = df[df['Year'] <= year]['Year Count']\n",
    "    if len(paper_count) == 0:\n",
    "        return 0\n",
    "    return paper_count.iloc[-1]\n",
    "\n",
    "# merge the dataframes and add a new column with the paper count\n",
    "merged = pd.merge(df, df1.drop_duplicates(subset=['Full name']), on='Full name', how='left')\n",
    "merged['Year Count'] = merged.apply(lambda x: get_paper_count(x['Full name'], x['Year_x']), axis=1)\n",
    "\n",
    "# Clean up and control check\n",
    "print(\"Number of rows in original table:\",df.shape[0], \" and umber of rows in merged table:\",merged.shape[0])\n",
    "print(\"Pct. of speakers whose information I was able to collect\",round(((df['Full name'].nunique()-df[~df['Full name'].isin(df1['Full name'])].shape[0])/df1['Full name'].nunique())*100,2),\"%\")\n",
    "merged['max_year_count'] = merged['max_year_count'].fillna(0)\n",
    "merged['First year paper'] = merged['First year paper'].fillna(0)\n",
    "merged = merged.drop(columns=['Year_y'])\n",
    "merged = merged.rename(columns={'Year_x': 'Year', 'Year Count': 'Paper Count', 'max_year_count': 'Max Paper Count'})\n",
    "merged.to_csv(os.path.join(filepath, \"factInvited.csv\"), index=False)\n",
    "print(\"The file is now saved\")\n",
    "merged.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ASPDAC', 'CHI', 'ECCV', 'HiPC', 'ic2s2', 'ICML', 'IJCAI', 'KDD',\n",
       "       'LICS', 'RTA', 'SC', 'SIGGRAPH', 'SODA', 'STOC', 'SWAT', 'WADS',\n",
       "       'WoLLIC', 'WWW', 'AAAI'], dtype=object)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged['Conference (short)'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proceedings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append all files in Data folder as a datafrom, and add a column for the file name without the extension and folder name\n",
    "df_new  = pd.read_csv(os.path.join(filepath,'factProceedings_init.csv'), encoding='utf-8')\n",
    "df_base  = pd.read_csv(os.path.join(filepath,'factProceedings.csv'), encoding='utf-8')\n",
    "\n",
    "# Find new names\n",
    "df_new = df_new[~df_new['Full name'].isin(df_base['Full name'])].reset_index(drop=True)\n",
    "df_new = df_new[df_new['Year'] >= 2003]\n",
    "df_new = df_new[~df_new['Conference (short)'].isin(['CVPR','ICIP'])]\n",
    "\n",
    "dblp_name = df_new['Full name'].str.replace(' ', '%20')\n",
    "dblp_name = dblp_name.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# drop nan values from the list\n",
    "dblp_name = dblp_name.dropna().reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data from dblp.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1257/1257 [48:41<00:00,  2.32s/it] \n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame(columns = ['Full name','Year','Year Count'])\n",
    "\n",
    "for Author in tqdm(dblp_name[463:]):\n",
    "    author_list = []\n",
    "    paper_list = []\n",
    "    \n",
    "    ##### Check if author is on dblp #####\n",
    "    dblp_URL = \"https://dblp.org/search?q=\" + Author\n",
    "    page = requests.get(dblp_URL)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    control_check = soup.find(id=\"completesearch-authors\").find_all(\"ul\",class_ = \"result-list\")\n",
    "    if len(control_check) > 0:\n",
    "        first_author = soup.find(id=\"completesearch-authors\").find_all(\"ul\",class_ = \"result-list\")[0].find_all(\"a\",href=True)[0]['href']\n",
    "        # print(Author,\" is on the webpage and the process continues...\")\n",
    "        \n",
    "        ##### Get info from author #####\n",
    "        author_page = requests.get(first_author)\n",
    "        soup_of_speaker = BeautifulSoup(author_page.content, \"html.parser\")\n",
    "\n",
    "        Year_list = []\n",
    "\n",
    "        sections = soup_of_speaker.find(id=\"publ-section\").find_all(\"div\", class_=\"hide-body\")\n",
    "        for s in range(0,len(sections)): # Nu går vi ind på hver enkelt sektion\n",
    "            rows_in_sections = sections[s].find_all('ul', class_=\"publ-list\")[0].findAll(True, {\"class\":['year','entry inproceedings toc','entry article toc','entry incollection toc', 'entry book toc','entry editor toc','entry reference toc']})\n",
    "            last_row_idx = 0\n",
    "            \n",
    "            for row in range(0,len(rows_in_sections)): # Nu går vi ind på hver enkelt række\n",
    "                #### Append year multipliers\n",
    "                if rows_in_sections[row].p == None:\n",
    "                    Year_list.append(rows_in_sections[row].text)\n",
    "                    paper_list.append(row-last_row_idx-1)\n",
    "                    last_row_idx = row \n",
    "                if row == len(rows_in_sections)-1: # den sidste linje i hver sektion\n",
    "                    paper_list.append(len(rows_in_sections)-last_row_idx-1)\n",
    "            \n",
    "            # remove all -1 values from the list\n",
    "            paper_list = [x for x in paper_list if x >= 0]\n",
    "                \n",
    "        # create a dataframe\n",
    "        df2 = pd.DataFrame(columns = ['Full name','Year','Year Count'])\n",
    "        # append full name to the dataframe\n",
    "        \n",
    "        df2['Year'] = Year_list\n",
    "        df2['Year Count'] = paper_list\n",
    "        df2['Full name'] = Author\n",
    "        df1 = df1.append(df2, ignore_index=True)\n",
    "    time.sleep(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(os.path.join(filepath,\"paper_count_Proceedings_new.csv\"), index=False)\n",
    "df3 = df1.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine data and save as factTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the initial factTable\n",
    "df  = pd.read_csv(os.path.join(filepath,'factProceedings_init.csv'), encoding='utf-8')\n",
    "# Load the table with paper count per year\n",
    "df2 = pd.read_csv(os.path.join(filepath,'paper_count_proceedings_old.csv'), encoding='utf-8')\n",
    "# concat df1 and df2\n",
    "df1 = pd.concat([df2,df3], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Full name'] = df1['Full name'].str.replace('%20', ' ')\n",
    "df1 = df1.drop_duplicates().reset_index(drop=True)\n",
    "df1['Year'] = df1['Year'].astype(int)\n",
    "df1['Year Count'] = df1['Year Count'].astype(int)\n",
    "\n",
    "df1 = df1.sort_values(by=['Year'], ascending=True)\n",
    "\n",
    "df1['Year Count'] = df1.groupby('Full name')['Year Count'].cumsum()\n",
    "\n",
    "df1['max_year_count'] = df1.groupby('Full name')['Year Count'].transform('max')\n",
    "df1['First year paper'] = df1.groupby('Full name')['Year'].transform('min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to get the paper count for a given name and year\n",
    "def get_paper_count(name, year):\n",
    "    df = df1[df1['Full name'] == name]\n",
    "    paper_count = df[df['Year'] <= year]['Year Count']\n",
    "    if len(paper_count) == 0:\n",
    "        return 0\n",
    "    return paper_count.iloc[-1]\n",
    "\n",
    "# merge the dataframes and add a new column with the paper count\n",
    "merged = pd.merge(df, df1.drop_duplicates(subset=['Full name']), on='Full name', how='left')\n",
    "merged['Year Count'] = merged.apply(lambda x: get_paper_count(x['Full name'], x['Year_x']), axis=1)\n",
    "\n",
    "# Clean up and control check\n",
    "print(\"Number of rows in original table:\",df.shape[0], \" and umber of rows in merged table:\",merged.shape[0])\n",
    "print(\"Pct. of speakers whose information I was able to collect\",round(((df['Full name'].nunique()-df[~df['Full name'].isin(df1['Full name'])].shape[0])/df1['Full name'].nunique())*100,2),\"%\")\n",
    "merged['max_year_count'] = merged['max_year_count'].fillna(0)\n",
    "merged['First year paper'] = merged['First year paper'].fillna(0)\n",
    "merged = merged.drop(columns=['Year_y'])\n",
    "merged = merged.rename(columns={'Year_x': 'Year', 'Year Count': 'Paper Count', 'max_year_count': 'Max Paper Count'})\n",
    "merged.to_csv(os.path.join(filepath, \"factProceedings.csv\"), index=False)\n",
    "print(\"The file is now saved\")\n",
    "merged.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d92ff415db99feb7da45e8748a5c23d5d44d2038e70d5b05ab6a02856c817802"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
