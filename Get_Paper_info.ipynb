{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Paper Info\n",
    "These notebook will get the paper info for each speakers in the conference. The attributes are: Number of papers (by year), first paper year, number of citation (by year), country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run setup.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invited"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append all files in Data folder as a datafrom, and add a column for the file name without the extension and folder name\n",
    "df_new  = pd.read_csv(os.path.join(filepath,'factInvited_init.csv'), encoding='utf-8')\n",
    "# df_base  = pd.read_csv(os.path.join(filepath,'factInvited.csv'), encoding='utf-8')\n",
    "\n",
    "# Find new names\n",
    "# df_new = df_new[~df_new['Full name'].isin(df_base['Full name'])].reset_index(drop=True)\n",
    "\n",
    "dblp_name = df_new['Full name'].str.replace(' ', '%20')\n",
    "dblp_name = dblp_name.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# drop nan values from the list\n",
    "dblp_name = dblp_name.dropna().reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data from dblp.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1480/1480 [1:28:16<00:00,  3.58s/it]  \n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame(columns = ['Full name','Year','Year Count'])\n",
    "\n",
    "for Author in tqdm(dblp_name):\n",
    "    author_list = []\n",
    "    paper_list = []\n",
    "    \n",
    "    ##### Check if author is on dblp #####\n",
    "    dblp_URL = \"https://dblp.org/search?q=\" + Author\n",
    "    page = requests.get(dblp_URL)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    control_check = soup.find(id=\"completesearch-authors\").find_all(\"ul\",class_ = \"result-list\")\n",
    "    if len(control_check) > 0:\n",
    "        first_author = soup.find(id=\"completesearch-authors\").find_all(\"ul\",class_ = \"result-list\")[0].find_all(\"a\",href=True)[0]['href']\n",
    "        # print(Author,\" is on the webpage and the process continues...\")\n",
    "        \n",
    "        ##### Get info from author #####\n",
    "        author_page = requests.get(first_author)\n",
    "        soup_of_speaker = BeautifulSoup(author_page.content, \"html.parser\")\n",
    "\n",
    "        Year_list = []\n",
    "\n",
    "        sections = soup_of_speaker.find(id=\"publ-section\").find_all(\"div\", class_=\"hide-body\")\n",
    "        for s in range(0,len(sections)): # Nu går vi ind på hver enkelt sektion\n",
    "            rows_in_sections = sections[s].find_all('ul', class_=\"publ-list\")[0].findAll(True, {\"class\":['year','entry inproceedings toc','entry article toc','entry incollection toc', 'entry book toc','entry editor toc','entry reference toc']})\n",
    "            last_row_idx = 0\n",
    "            \n",
    "            for row in range(0,len(rows_in_sections)): # Nu går vi ind på hver enkelt række\n",
    "                #### Append year multipliers\n",
    "                if rows_in_sections[row].p == None:\n",
    "                    Year_list.append(rows_in_sections[row].text)\n",
    "                    paper_list.append(row-last_row_idx-1)\n",
    "                    last_row_idx = row \n",
    "                if row == len(rows_in_sections)-1: # den sidste linje i hver sektion\n",
    "                    paper_list.append(len(rows_in_sections)-last_row_idx-1)\n",
    "            \n",
    "            # remove all -1 values from the list\n",
    "            paper_list = [x for x in paper_list if x >= 0]\n",
    "                \n",
    "        # create a dataframe\n",
    "        df2 = pd.DataFrame(columns = ['Full name','Year','Year Count'])\n",
    "        # append full name to the dataframe\n",
    "        \n",
    "        df2['Year'] = Year_list\n",
    "        df2['Year Count'] = paper_list\n",
    "        df2['Full name'] = Author\n",
    "        df1 = df1.append(df2, ignore_index=True)\n",
    "    time.sleep(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(os.path.join(filepath,\"paper_count_Invited_new.csv\"), index=False)\n",
    "df3 = df1.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine data and save as factTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the initial factTable\n",
    "df  = pd.read_csv(os.path.join(filepath,'factInvited_init.csv'), encoding='utf-8')\n",
    "# Load the table with paper count per year\n",
    "# df2 = pd.read_csv(os.path.join(filepath,'paper_count_per_year_proceedings.csv'), encoding='utf-8')\n",
    "# concat df1 and df2\n",
    "# df1 = pd.concat([df2,df3], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Full name'] = df1['Full name'].str.replace('%20', ' ')\n",
    "df1 = df1.drop_duplicates().reset_index(drop=True)\n",
    "df1['Year'] = df1['Year'].astype(int)\n",
    "df1['Year Count'] = df1['Year Count'].astype(int)\n",
    "\n",
    "df1 = df1.sort_values(by=['Year'], ascending=True)\n",
    "\n",
    "df1['Year Count'] = df1.groupby('Full name')['Year Count'].cumsum()\n",
    "\n",
    "df1['max_year_count'] = df1.groupby('Full name')['Year Count'].transform('max')\n",
    "df1['First year paper'] = df1.groupby('Full name')['Year'].transform('min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in original table: 1816  and umber of rows in merged table: 1816\n",
      "Pct. of speakers whose information I was able to collect 109.63 %\n",
      "The file is now saved\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Full name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Conference (short)</th>\n",
       "      <th>First name</th>\n",
       "      <th>Middle name</th>\n",
       "      <th>Last name</th>\n",
       "      <th>gender</th>\n",
       "      <th>Paper Count</th>\n",
       "      <th>Max Paper Count</th>\n",
       "      <th>First year paper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Atsushi Asada</td>\n",
       "      <td>1995</td>\n",
       "      <td>ASPDAC</td>\n",
       "      <td>Atsushi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Asada</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2011.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jim Meadlock</td>\n",
       "      <td>1995</td>\n",
       "      <td>ASPDAC</td>\n",
       "      <td>Jim</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Meadlock</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John Darringer</td>\n",
       "      <td>1995</td>\n",
       "      <td>ASPDAC</td>\n",
       "      <td>John</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Darringer</td>\n",
       "      <td>M</td>\n",
       "      <td>11</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1967.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tatsuo Izawa</td>\n",
       "      <td>1997</td>\n",
       "      <td>ASPDAC</td>\n",
       "      <td>Tatsuo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Izawa</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Daniel D. Gajski</td>\n",
       "      <td>1997</td>\n",
       "      <td>ASPDAC</td>\n",
       "      <td>Daniel</td>\n",
       "      <td>D.</td>\n",
       "      <td>Gajski</td>\n",
       "      <td>M</td>\n",
       "      <td>119</td>\n",
       "      <td>222.0</td>\n",
       "      <td>1978.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Neil Weste</td>\n",
       "      <td>1997</td>\n",
       "      <td>ASPDAC</td>\n",
       "      <td>Neil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Weste</td>\n",
       "      <td>M</td>\n",
       "      <td>12</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1978.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kazuo Yano</td>\n",
       "      <td>2002</td>\n",
       "      <td>ASPDAC</td>\n",
       "      <td>Kazuo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yano</td>\n",
       "      <td>M</td>\n",
       "      <td>7</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Martin F.H. Schuurmans</td>\n",
       "      <td>2002</td>\n",
       "      <td>ASPDAC</td>\n",
       "      <td>Martin</td>\n",
       "      <td>F.H.</td>\n",
       "      <td>Schuurmans</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gadi Singer</td>\n",
       "      <td>1998</td>\n",
       "      <td>ASPDAC</td>\n",
       "      <td>Gadi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Singer</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1990.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hisashi Yamada</td>\n",
       "      <td>1998</td>\n",
       "      <td>ASPDAC</td>\n",
       "      <td>Hisashi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yamada</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1983.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Full name  Year Conference (short) First name Middle name  \\\n",
       "0           Atsushi Asada  1995             ASPDAC    Atsushi         NaN   \n",
       "1            Jim Meadlock  1995             ASPDAC        Jim         NaN   \n",
       "2          John Darringer  1995             ASPDAC       John         NaN   \n",
       "3            Tatsuo Izawa  1997             ASPDAC     Tatsuo         NaN   \n",
       "4        Daniel D. Gajski  1997             ASPDAC     Daniel          D.   \n",
       "5              Neil Weste  1997             ASPDAC       Neil         NaN   \n",
       "6              Kazuo Yano  2002             ASPDAC      Kazuo         NaN   \n",
       "7  Martin F.H. Schuurmans  2002             ASPDAC     Martin        F.H.   \n",
       "8             Gadi Singer  1998             ASPDAC       Gadi         NaN   \n",
       "9          Hisashi Yamada  1998             ASPDAC    Hisashi         NaN   \n",
       "\n",
       "    Last name gender  Paper Count  Max Paper Count  First year paper  \n",
       "0       Asada      M            0              1.0            2011.0  \n",
       "1    Meadlock      M            0              0.0               0.0  \n",
       "2   Darringer      M           11             27.0            1967.0  \n",
       "3       Izawa      M            0              1.0            2018.0  \n",
       "4      Gajski      M          119            222.0            1978.0  \n",
       "5       Weste      M           12             27.0            1978.0  \n",
       "6        Yano      M            7             37.0            1996.0  \n",
       "7  Schuurmans      M            1              1.0            2002.0  \n",
       "8      Singer      M            2              9.0            1990.0  \n",
       "9      Yamada      M            2              5.0            1983.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a function to get the paper count for a given name and year\n",
    "def get_paper_count(name, year):\n",
    "    df = df1[df1['Full name'] == name]\n",
    "    paper_count = df[df['Year'] <= year]['Year Count']\n",
    "    if len(paper_count) == 0:\n",
    "        return 0\n",
    "    return paper_count.iloc[-1]\n",
    "\n",
    "# merge the dataframes and add a new column with the paper count\n",
    "merged = pd.merge(df, df1.drop_duplicates(subset=['Full name']), on='Full name', how='left')\n",
    "merged['Year Count'] = merged.apply(lambda x: get_paper_count(x['Full name'], x['Year_x']), axis=1)\n",
    "\n",
    "# Clean up and control check\n",
    "print(\"Number of rows in original table:\",df.shape[0], \" and umber of rows in merged table:\",merged.shape[0])\n",
    "print(\"Pct. of speakers whose information I was able to collect\",round(((df['Full name'].nunique()-df[~df['Full name'].isin(df1['Full name'])].shape[0])/df1['Full name'].nunique())*100,2),\"%\")\n",
    "merged['max_year_count'] = merged['max_year_count'].fillna(0)\n",
    "merged['First year paper'] = merged['First year paper'].fillna(0)\n",
    "merged = merged.drop(columns=['Year_y'])\n",
    "merged = merged.rename(columns={'Year_x': 'Year', 'Year Count': 'Paper Count', 'max_year_count': 'Max Paper Count'})\n",
    "merged.to_csv(os.path.join(filepath, \"factInvited.csv\"), index=False)\n",
    "print(\"The file is now saved\")\n",
    "merged.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proceedings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append all files in Data folder as a datafrom, and add a column for the file name without the extension and folder name\n",
    "df_new  = pd.read_csv(os.path.join(filepath,'factProceedings_init.csv'), encoding='utf-8')\n",
    "df_base  = pd.read_csv(os.path.join(filepath,'factProceedings.csv'), encoding='utf-8')\n",
    "\n",
    "# Find new names\n",
    "df_new = df_new[~df_new['Full name'].isin(df_base['Full name'])].reset_index(drop=True)\n",
    "\n",
    "dblp_name = df_new['Full name'].str.replace(' ', '%20')\n",
    "dblp_name = dblp_name.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# drop nan values from the list\n",
    "dblp_name = dblp_name.dropna().reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data from dblp.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 2143/36343 [1:19:48<26:06:38,  2.75s/it]"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame(columns = ['Full name','Year','Year Count'])\n",
    "\n",
    "for Author in tqdm(dblp_name):\n",
    "    author_list = []\n",
    "    paper_list = []\n",
    "    \n",
    "    ##### Check if author is on dblp #####\n",
    "    dblp_URL = \"https://dblp.org/search?q=\" + Author\n",
    "    page = requests.get(dblp_URL)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    control_check = soup.find(id=\"completesearch-authors\").find_all(\"ul\",class_ = \"result-list\")\n",
    "    if len(control_check) > 0:\n",
    "        first_author = soup.find(id=\"completesearch-authors\").find_all(\"ul\",class_ = \"result-list\")[0].find_all(\"a\",href=True)[0]['href']\n",
    "        # print(Author,\" is on the webpage and the process continues...\")\n",
    "        \n",
    "        ##### Get info from author #####\n",
    "        author_page = requests.get(first_author)\n",
    "        soup_of_speaker = BeautifulSoup(author_page.content, \"html.parser\")\n",
    "\n",
    "        Year_list = []\n",
    "\n",
    "        sections = soup_of_speaker.find(id=\"publ-section\").find_all(\"div\", class_=\"hide-body\")\n",
    "        for s in range(0,len(sections)): # Nu går vi ind på hver enkelt sektion\n",
    "            rows_in_sections = sections[s].find_all('ul', class_=\"publ-list\")[0].findAll(True, {\"class\":['year','entry inproceedings toc','entry article toc','entry incollection toc', 'entry book toc','entry editor toc','entry reference toc']})\n",
    "            last_row_idx = 0\n",
    "            \n",
    "            for row in range(0,len(rows_in_sections)): # Nu går vi ind på hver enkelt række\n",
    "                #### Append year multipliers\n",
    "                if rows_in_sections[row].p == None:\n",
    "                    Year_list.append(rows_in_sections[row].text)\n",
    "                    paper_list.append(row-last_row_idx-1)\n",
    "                    last_row_idx = row \n",
    "                if row == len(rows_in_sections)-1: # den sidste linje i hver sektion\n",
    "                    paper_list.append(len(rows_in_sections)-last_row_idx-1)\n",
    "            \n",
    "            # remove all -1 values from the list\n",
    "            paper_list = [x for x in paper_list if x >= 0]\n",
    "                \n",
    "        # create a dataframe\n",
    "        df2 = pd.DataFrame(columns = ['Full name','Year','Year Count'])\n",
    "        # append full name to the dataframe\n",
    "        \n",
    "        df2['Year'] = Year_list\n",
    "        df2['Year Count'] = paper_list\n",
    "        df2['Full name'] = Author\n",
    "        df1 = df1.append(df2, ignore_index=True)\n",
    "    time.sleep(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(os.path.join(filepath,\"paper_count_Proceedings_new.csv\"), index=False)\n",
    "df3 = df1.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine data and save as factTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the initial factTable\n",
    "df  = pd.read_csv(os.path.join(filepath,'factProceedings_init.csv'), encoding='utf-8')\n",
    "# Load the table with paper count per year\n",
    "df2 = pd.read_csv(os.path.join(filepath,'paper_count_proceedings_old.csv'), encoding='utf-8')\n",
    "# concat df1 and df2\n",
    "df1 = pd.concat([df2,df3], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Full name'] = df1['Full name'].str.replace('%20', ' ')\n",
    "df1 = df1.drop_duplicates().reset_index(drop=True)\n",
    "df1['Year'] = df1['Year'].astype(int)\n",
    "df1['Year Count'] = df1['Year Count'].astype(int)\n",
    "\n",
    "df1 = df1.sort_values(by=['Year'], ascending=True)\n",
    "\n",
    "df1['Year Count'] = df1.groupby('Full name')['Year Count'].cumsum()\n",
    "\n",
    "df1['max_year_count'] = df1.groupby('Full name')['Year Count'].transform('max')\n",
    "df1['First year paper'] = df1.groupby('Full name')['Year'].transform('min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to get the paper count for a given name and year\n",
    "def get_paper_count(name, year):\n",
    "    df = df1[df1['Full name'] == name]\n",
    "    paper_count = df[df['Year'] <= year]['Year Count']\n",
    "    if len(paper_count) == 0:\n",
    "        return 0\n",
    "    return paper_count.iloc[-1]\n",
    "\n",
    "# merge the dataframes and add a new column with the paper count\n",
    "merged = pd.merge(df, df1.drop_duplicates(subset=['Full name']), on='Full name', how='left')\n",
    "merged['Year Count'] = merged.apply(lambda x: get_paper_count(x['Full name'], x['Year_x']), axis=1)\n",
    "\n",
    "# Clean up and control check\n",
    "print(\"Number of rows in original table:\",df.shape[0], \" and umber of rows in merged table:\",merged.shape[0])\n",
    "print(\"Pct. of speakers whose information I was able to collect\",round(((df['Full name'].nunique()-df[~df['Full name'].isin(df1['Full name'])].shape[0])/df1['Full name'].nunique())*100,2),\"%\")\n",
    "merged['max_year_count'] = merged['max_year_count'].fillna(0)\n",
    "merged['First year paper'] = merged['First year paper'].fillna(0)\n",
    "merged = merged.drop(columns=['Year_y'])\n",
    "merged = merged.rename(columns={'Year_x': 'Year', 'Year Count': 'Paper Count', 'max_year_count': 'Max Paper Count'})\n",
    "merged.to_csv(os.path.join(filepath, \"factProceedings.csv\"), index=False)\n",
    "print(\"The file is now saved\")\n",
    "merged.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d92ff415db99feb7da45e8748a5c23d5d44d2038e70d5b05ab6a02856c817802"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
